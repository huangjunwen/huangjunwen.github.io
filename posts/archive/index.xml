<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>archive on Coder Papa</title>
    <link>http://127.0.0.1:1313/posts/archive/</link>
    <description>Recent content in archive on Coder Papa</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 01 Jan 2016 00:00:00 +0800</lastBuildDate><atom:link href="http://127.0.0.1:1313/posts/archive/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kademlia 简介</title>
      <link>http://127.0.0.1:1313/posts/archive/kademlia/</link>
      <pubDate>Sat, 12 Sep 2020 12:23:00 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/posts/archive/kademlia/</guid>
      <description>Kademlia 是一种 p2p 网络的分布式哈希表 (DHT: distributed hash table). 有别于单机版的 hash table, p2p DHT 需要将 key-value 键值对存放在大量的 (但不稳定的) p2p 节点上的, 并提供远程的 (RPC) 存取方法.
键空间 (Key Space) Kademlia 的 key 是 n-bit 的 unsigned int, 故取值范围为 \([0, 2^n-1]\). 例如原论文中使用 160 bits, 又如 ipfs 使用的是 256 bits.
在键空间上定义 “距离” 为两个 key 之间的 异或 (结果仍然为 n-bit unsigned int):
\[ Dis(A, B) = A ⊕ B \]
NOTE: 使用异或作为距离有一些数学属性, 见下面详述, 这里先跳过，我们先看个例子
上图是一个 n 为 4 的示例，其 key 取值为 [0, 15] （或 [0b0000, 0b1111]），以一棵满二叉树的形式呈现.</description>
    </item>
    
    <item>
      <title>写了一个 MySQL 数据表和查询的 go 代码生成器</title>
      <link>http://127.0.0.1:1313/posts/archive/sqlw-mysql/</link>
      <pubDate>Mon, 10 Sep 2018 20:51:26 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/posts/archive/sqlw-mysql/</guid>
      <description>项目地址 https://github.com/huangjunwen/sqlw-mysql
动机 最近这段时间开始用 go 写网站，遇到各种新老问题。其中一个老问题是如何访问 MySQL 数据库。
使用 ORM (Object Relationship Mapping) 大致浏览了一些热门的实现，感觉不是很合眼缘，跟动态语言的实现（例如 SQLAlchemy ）差不少。
ORM 的特点在于使用程序员熟悉的对象概念抽象数据库关系，使之成为可编程的对象，提供使用上的便利：
 构造查询的便利，用户一般只需要指定需要查询的对象（一般对应数据库表），或者关系（一般对应 JOIN），还可以按需要增添查询条件，ORM 即可推导出需要执行的语句：  sess.query(User) # SELECT user.id, ... FROM user sess.query(Employee.User) # SELECT employee.id, ... FROM employee JOIN user ON ... sess.query(User).filter(User.name==xxx) # SELECT user.id, ... FROM user WHERE name=xxx sess.query(User).options(joinedload(Employee)).order_by(...) # ...  查询后的便利，结果集会被重新组装成对象，后续仍只需继续在这些对象上操作即可。  这样理想状态下涉及数据库的操作就被完全封装到一个闭环里头。然而数据库关系其实并不简单，建立一个表达力十足的映射模型即是使用 python 这种表达力很强的动态语言都很复杂（看看这个函数），何况 go 这种既缺乏元编程能力也缺乏语法糖的语言呢。
因此我所见的实现往往只能退而求其次，只实现一些基本常用的功能。
直接使用 SQL 除了使用 ORM 另外一种方法是直接面对关系数据库/SQL 本身，例如有很多人（声称）直接使用 sqlx，但我感觉全部手写会不会也挺麻烦重复的呢？
所以有一些工具能帮忙生成代码，例如 xo，连接上数据库直接导出 schema 就能生成基本的 CRUD 访问代码，同时也可以根据它的 SQL DSL 生成 SQL 的 wrapper code。整个过程一目了然，没有层层封装的不透明感，生成代码的效率也高，虽然需要手写 SQL，但代码生成过程是经过实际数据库验证的，这就相当可靠了。</description>
    </item>
    
    <item>
      <title>Greenlet 原理</title>
      <link>http://127.0.0.1:1313/posts/archive/greenlet/</link>
      <pubDate>Thu, 15 Mar 2018 09:05:51 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/posts/archive/greenlet/</guid>
      <description>原理 我们知道，操作系统会给每一个线程分配一个独立的堆栈，它们各自独立运作，记录着该线程的各类运行状态：如函数本地变量，函数返回地址，寄存器状态等等各种上下文；从这个角度看，堆栈几乎就等价于线程
那么假如想要在用户态实现轻量级的类线程，就同样需要给它们分配独立堆栈，并提供方法在它们之间切换
Greenlet 就是 cpython 上的一种轻量级线程（协程）的实现，因为 cpython 是用 c 实现的，所以这就要求 Greenlet 的实现要跟 c 那一套保持一致，要让协程里运行的代码感觉自己跑在一个真正的 c 堆栈上
Greenlet 的做法是这样的：当一个 greenlet 运行时，它的堆栈区间数据将会完整地恢复放在 c 堆栈上，让它“原生态”地执行；若它被挂起，则有可能其部分或全部堆栈区间的数据会被拷贝到堆上保存；这是因为所有同一个线程的 greenlets 共享同一个 c 堆栈的地址空间，它们的堆栈区间会有可能有交集重叠
我们主要关注 PyGreenlet 的这几个字段来讨论实现原理：
 stack_stop: 该 greenlet 堆栈区间 底 部地址（旧数据方向） stack_start: 该 greenlet 堆栈区间 顶 部地址（新数据方向） stack_prev: greenlet 链表 指针，见下节说明 stack_copy: 该 greenlet 堆栈区间在堆上的拷贝 stack_saved: 该 greenlet 堆栈区间在堆上的拷贝的长度  greenlet 链表 如前所叙述，只有当前运行的 greenlet 是保证其堆栈区间完整地置于 c 堆栈上，其它挂起的 greenlets 的堆栈区间数据则是有可能部分或全部地拷贝到了堆上保存；
那么任意时刻，c 堆栈就会由多个 greenlets 的部分或全部堆栈区间组成（这些区间有可能是紧贴着的，也可能中间有空隙，但必定不能重叠），Greenlet 库维护一个 greenlet 链表来表达 c 堆栈上这些区间的前后关系，该链表就是由 stack_prev 串联而成的，例如</description>
    </item>
    
    <item>
      <title>Vault Database Secret Backend</title>
      <link>http://127.0.0.1:1313/posts/archive/vault-database-secret-backend/</link>
      <pubDate>Sat, 10 Jun 2017 16:46:36 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/posts/archive/vault-database-secret-backend/</guid>
      <description>在当前版本（v0.7.2）这个 backend 还处于 beta 状态；这个 backend 应该是用来统一之前版本中各种数据库的 secret backend 的；使用前需要挂载 vault mount database，这里用 MySQL 来演示它的主要工作流程：
 写入数据库配置，路径在 database/config/$db_name ，主要参数有：  db_name 这个配置的名字 plugin_name 指定用何种数据库 driver plugin（mysql/postgres 等） connection_url 指定连接参数（注：这个连接参数是用来连数据库以创建用户的，需要有对应的权限） allowed_roles 指定的是允许哪些角色使用此配置（角色是啥下一步就会说明） 安全考虑：这个路径即使读权限也需要严格限制，因为它包含了相当高权限的数据库用户信息 例子：   $ export db_name=&amp;quot;test&amp;quot; $ export role_name=&amp;quot;test_reader&amp;quot; $ export plugin_name=&amp;quot;mysql-legacy-database-plugin&amp;quot; # mysql 有多个 plugin，它们的区别这是创建的数据库用户名最大长度不一样，因为不同版本用户名长度有变化 $ export connection_url=&amp;quot;root:password@tcp(127.0.0.1:3306)/&amp;quot; # 不要忘了最后的 / $ vault write database/config/$db_name \ &amp;gt; plugin_name=$plugin_name \ &amp;gt; connection_url=$connection_url \ &amp;gt; allowed_roles=&amp;quot;$role_name&amp;quot; ... The following warnings were returned from the Vault server: * Read access to this endpoint should be controlled via ACLs as it will return the connection details as is, including passwords, if any.</description>
    </item>
    
    <item>
      <title>Vault 介绍</title>
      <link>http://127.0.0.1:1313/posts/archive/vault/</link>
      <pubDate>Wed, 07 Jun 2017 08:14:18 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/posts/archive/vault/</guid>
      <description>之前一篇文章介绍了 Hashicorp Vault 的解封/密封算法。这篇打算记录一下这个软件的其它方面。当前最新版本为 v0.7.2 。
Vault 是一个相当复杂的系统，总括而言，它是一个集中管理各类敏感信息（如密码/Key/证书等等）的软件（服务）。Vault 采用类似 Unix “一切皆文件” 的方式组织及暴露各类信息：所有操作都是对某个路径的 read/write （实际上是对某个 HTTP 路径 POST/GET/LIST/DELETE 等） ，例如：
 /sys 目录下是各种配置路径，此目录不可被卸载，其下路径各有用途，如 /sys/seal 和 /sys/unseal 这两个路径是用来密封/解封 vault 的。 /secret 目录下挂载的是 Generic Secret Backend，用于存放一般用途的敏感信息，其下路径组织结构由用户自行决定，我们平时实际使用访问最多的应该也是这个。 … 更多目录路径说明可参看 API 文档  读取/写入的数据一般都是 JSON 格式。
Backends Vault 主要由几类 backends 合作组成：
Auth -&amp;gt; Secret -&amp;gt; Storage(Physical) -&amp;gt; Audit
认证 -&amp;gt; 实际操作 -&amp;gt; 落盘储存 -&amp;gt; 日志
Auth(entication) Backend Auth Backend 完成的是认证工作：访问者是谁。有多种可通过挂载添加，默认情况下它们会挂载在 auth/&amp;lt;type&amp;gt; 下，以下是其中一些认证方式：
 token 这个 Backend 是 Vault 的核心认证方式，默认挂载，不可卸载，非常重要，下一小节详细描述 userpass 用户名密码认证 github 用 Github 的认证服务 cert 用 tls 证书认证 approle TODO  Token （令牌） 对外部而言，顾名思义，有了令牌就能通行，它是访问者身份的象征；实际上，Vault 对外 API 中绝大部分（除了像 seal/unseal 这种）都需要令牌才能访问：访问的 HTTP 请求头部需要加上 X-Vault-Token: xxxxxx （命令行其实也是调用 HTTP API 的，Token 保存在 ~/.</description>
    </item>
    
    <item>
      <title>微服务中的认证 (authentication) 问题</title>
      <link>http://127.0.0.1:1313/posts/archive/authentication_in_microservice/</link>
      <pubDate>Sun, 14 May 2017 19:14:51 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/posts/archive/authentication_in_microservice/</guid>
      <description>这帖子有意思 JSON Web token vs. Session
“单纯”的 JWT，其实跟 client side session 没啥区别，它的优缺点都一样：
Pros：
 服务端不需要储存 session 数据 stateless 因为不用访问任何储存服务，验证过程超快速 易于 scale up  Cons:
 session 很难被主动清除（除非过期） 所有信息都暴露在外（或者有暴露的危险）  最终我觉得一个比较好的办法是结合这两者：对外使用 session，提供一个 opaque 的 token (reference token) 作为 session id，在网关中做翻译过程，将这个 reference token 转换成真实的 jwt，然后在网关内的服务就都使用 jwt。
见 muCon 2016: Authentication in Microservice Systems By David Borsos</description>
    </item>
    
    <item>
      <title>Shamir Secret Sharding</title>
      <link>http://127.0.0.1:1313/posts/archive/shamir-secret-sharding/</link>
      <pubDate>Sun, 23 Apr 2017 09:27:43 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/posts/archive/shamir-secret-sharding/</guid>
      <description>Hashicorp 这家公司的产品都很有意思，其中 Vault 是一个用来集中管理敏感信息（密码，各种 token，证书，key 等等）的工具。
Vault server 运行起来之后有两种状态：seal/unseal (密封/解封) ，这是因为：
Vault 的数据是加密储存在磁盘上的：由 encryption key 加密，这个 encryption key 是由 master key 加密储存在磁盘上，而 master key 是不存放在磁盘上。所以当 Vault server 刚启动时，由于 master key 未知，故 encryption key 以及实际数据都是无法被解密访问的，这种状态就称之为seal (密封) ，unseal(解封) 就是重建 master key 的过程。
由于 master key 太重要了，Vault 使用所谓的 Shamir’s Secret Sharing 算法把这个 master key 切分并分发给 n 个人，只有当这 n 个人里的最少 k 个人授权提供他们持有的部分，vault 才能重构出这个 master key，这个算法挺有趣，所以记录下来：
目标 密码 \(S\) 需要切分成 \(n\) 份： \(S_1, S_2, ... S_n\)</description>
    </item>
    
    <item>
      <title>ASN.1</title>
      <link>http://127.0.0.1:1313/posts/archive/asn.1/</link>
      <pubDate>Wed, 01 Feb 2017 09:19:40 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/posts/archive/asn.1/</guid>
      <description>记法和编码 ASN.1（Abstract syntax notation one） 是一个对数据（类型/值）的记法和编码的祖父级标准；制定几十年而依然健在且广泛使用。
对比一下 JSON（Javascript Object Notation），JSON 中的记法和编码是等价的，即它的记法就是编码。
而 ASN.1 中记法和编码是不一样的，记法主要是为人类服务，用于描述，是抽象且实现无关的，例如 （摘自这里）：
AirlineFlight ::= SEQUENCE { airline IA5String, flight NumericString, seats SEQUENCE { maximum INTEGER, occupied INTEGER, vacant INTEGER }, airport SEQUENCE { origin IA5String, stop1 [0] IA5String OPTIONAL, stop2 [1] IA5String OPTIONAL, destination IA5String }, crewsize ENUMERATED { six (6), eight (8), ten (10) }, cancel BOOLEAN DEFAULT FALSE }. 而编码则是具体实现序列化以及反序列化的操作，ASN.1 有很多种编码方式，例如：
 Basic Encoding Rule (BER) Canonical Encoding Rules (CER) Distinguished Encoding Rules (DER) XML Encoding Rules (XER) Packed Encoding Rules (PER) …  这篇笔记主要记录 ASN.</description>
    </item>
    
    <item>
      <title>RSA 简介</title>
      <link>http://127.0.0.1:1313/posts/archive/rsa/</link>
      <pubDate>Tue, 24 Jan 2017 11:52:55 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/posts/archive/rsa/</guid>
      <description>主要算法 RSA 的原理是在于能够找到三个很大的正整数 \(e,d,n\) 使得对于任何 \(0 \le m \lt n\)：
\[ (m^e)^d \equiv m \pmod{n} \]
其中公钥为 \((n,e)\)，可以发送给任何人；私钥为 \((n,d)\)，只能由所有者掌握。RSA 支持 4 种操作：加密/解密，签名/验证签名。
加密 首先用一些编码手段把需要加密的信息转换成整数 \(m\)，用公钥中的两个参数计算
\[ c = m^e \pmod{n} \]
其中 \(c\) 就是加密后的信息了。
解密 中学知识温习时间：
\[ \begin{align} ab \pmod{n} &amp;amp;= (xn+a_r)(yn+b_r) \pmod{n} \\ &amp;amp;= a_r b_r \pmod{n} \\ &amp;amp;= (a \pmod{n})(b \pmod{n}) \pmod{n} \end{align} \]
即在模运算中，只要算余数就可以了。
因此，由私钥所有者计算
\[ \begin{align} c^d \pmod{n} &amp;amp;= (m^e \pmod{n})^d \pmod{n} \\ &amp;amp;= (m^e)^d \pmod{n} \\ &amp;amp;= m \pmod{n} \end{align} \]</description>
    </item>
    
    <item>
      <title>用 iptables 来配置 port knocking</title>
      <link>http://127.0.0.1:1313/posts/archive/port-knocking-using-iptables/</link>
      <pubDate>Tue, 20 Dec 2016 10:20:54 +0800</pubDate>
      
      <guid>http://127.0.0.1:1313/posts/archive/port-knocking-using-iptables/</guid>
      <description>对于正式环境的服务器来说，每当查看到 auth.log 里头那些撞大运的 ssh 登录尝试，心里总是有点惴惴不安的。虽然 public key authentication 号称安全，但是谁说得准呢？而且不知道配置里会不会有错误，要是有多一层的防护总是好的。
以前听说过 Port knocking 这种技术了，大致的思路就是设定一系列随机端口（例如：7421，3411，9088等等）作为暗号，用户在访问服务器之前，要依次“敲”一下这几个端口（即相继发送网络包到这几个端口上），这些端口当然是关闭状态啦，但服务器上可以侦察得到这些敲门，如果暗号对了，就给访问者 ip 开放服务端口（例如22）。
还有一些更高级的，例如在网络包里存放加密信息等，不过这就复杂了，暂且不表。
一般要实现这样的功能，需要有独立的 deamon 程序跑在后台检查日志，但有个问题，如果这个 deamon 不够健壮挂了的话，就再也没人上得去了。
前段时间看到 DigitalOcean 上一篇单纯使用 iptables 就能实现 Port knocking 的教程，不需要单独开发 deamon，只要配置 iptables 的 rules 就能实现这样的功能，觉得很实用，分享在此：
https://www.digitalocean.com/community/tutorials/how-to-configure-port-knocking-using-only-iptables-on-an-ubuntu-vps
不过我用的时候发现个问题，就是 tcp 包在发送的时候，好像一次过会发送多个包，这样敲门的序列就会变成类似：
7421 7421 3411 9088 9088 9088 ... 所以我把 rules 改成接纳每个端口可以连续 N 次，只要下一个不一样的是正确的就可以接受：
#!/bin/bash PORT1=xxxx PORT2=xxxx PORT3=xxxx # reset firewall iptables -F iptables -X iptables -P INPUT ACCEPT iptables -P FORWARD ACCEPT iptables -P OUTPUT ACCEPT # create new chains used by port knocking iptables -N KNOCKING iptables -N GATE1 iptables -N GATE2 iptables -N GATE3 iptables -N PASSED # accept current connections (keep current SSH connections) iptables -A INPUT -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT # accept local machine&amp;#39;s connection iptables -A INPUT -i lo -j ACCEPT # accept http/https or other exported services iptables -A INPUT -p tcp --dport 80 -j ACCEPT iptables -A INPUT -p tcp --dport 443 -j ACCEPT # now pass all other to the KNOCKING chain iptables -A INPUT -j KNOCKING # KNOCKING dispatch iptables -A KNOCKING -m recent --reap --rcheck --seconds 3600 --name AUTH3 -j PASSED iptables -A KNOCKING -m recent --reap --rcheck --seconds 10 --name AUTH2 -j GATE3 iptables -A KNOCKING -m recent --reap --rcheck --seconds 10 --name AUTH1 -j GATE2 iptables -A KNOCKING -j GATE1 iptables -A GATE1 -p tcp --dport $PORT1 -m recent --name AUTH1 --set -j DROP iptables -A GATE1 -j DROP iptables -A GATE2 -p tcp --dport $PORT1 -j DROP # allow $PORT1 duplication iptables -A GATE2 -m recent --name AUTH1 --remove iptables -A GATE2 -p tcp --dport $PORT2 -m recent --name AUTH2 --set -j DROP iptables -A GATE2 -j GATE1 iptables -A GATE3 -p tcp --dport $PORT2 -j DROP # allow $PORT2 duplication iptables -A GATE3 -m recent --name AUTH2 --remove iptables -A GATE3 -p tcp --dport $PORT3 -m recent --name AUTH3 --set -j DROP iptables -A GATE3 -j GATE1 iptables -A PASSED -p tcp --dport $PORT3 -j DROP # allow $PORT3 duplication iptables -A PASSED -p tcp --dport 22 -j ACCEPT iptables -A PASSED -j DROP 另外还有些修改，例如 AUTH3 的时候，允许用户有一个小时（3600秒）的时间可以随意连接 22 端口。</description>
    </item>
    
  </channel>
</rss>
